{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kinaya18/Hands-on-Machine-Learning-with-Scikit-Learn-Keras-TensorFlow/blob/main/Neural%20Networks%20and%20Deep%20Learning/Chapter_19.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GdUc1eJWtv8"
      },
      "source": [
        "# **Chapter 19 â€“ Training and Deploying TensorFlow Models at Scale**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r53cj-jDWtwD"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "IS_COLAB = \"google.colab\" in sys.modules\n",
        "IS_KAGGLE = \"kaggle_secrets\" in sys.modules\n",
        "\n",
        "if IS_COLAB or IS_KAGGLE:\n",
        "    !echo \"deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" > /etc/apt/sources.list.d/tensorflow-serving.list\n",
        "    !curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | apt-key add -\n",
        "    !apt update && apt-get install -y tensorflow-model-server\n",
        "    %pip install -q -U tensorflow-serving-api\n",
        "\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "if not tf.config.list_physical_devices('GPU'):\n",
        "    print(\"No GPU was detected. CNNs can be very slow without a GPU.\")\n",
        "    if IS_COLAB:\n",
        "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
        "    if IS_KAGGLE:\n",
        "        print(\"Go to Settings > Accelerator and select GPU.\")\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"deploy\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LR52bQ9OWtwF"
      },
      "source": [
        "# Deploying TensorFlow models to TensorFlow Serving (TFS)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gguxK0gyWtwF"
      },
      "source": [
        "## Save/Load a `SavedModel`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfAWmMmKWtwG"
      },
      "outputs": [],
      "source": [
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
        "X_train_full = X_train_full[..., np.newaxis].astype(np.float32) / 255.\n",
        "X_test = X_test[..., np.newaxis].astype(np.float32) / 255.\n",
        "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "X_new = X_test[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xiQkVYHNWtwG",
        "outputId": "b95a004d-44e6-44b8-bed5-6bbf22586e54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1719/1719 [==============================] - 2s 1ms/step - loss: 1.1140 - accuracy: 0.7066 - val_loss: 0.3715 - val_accuracy: 0.9024\n",
            "Epoch 2/10\n",
            "1719/1719 [==============================] - 1s 713us/step - loss: 0.3695 - accuracy: 0.8981 - val_loss: 0.2990 - val_accuracy: 0.9144\n",
            "Epoch 3/10\n",
            "1719/1719 [==============================] - 1s 718us/step - loss: 0.3154 - accuracy: 0.9100 - val_loss: 0.2651 - val_accuracy: 0.9272\n",
            "Epoch 4/10\n",
            "1719/1719 [==============================] - 1s 706us/step - loss: 0.2765 - accuracy: 0.9223 - val_loss: 0.2436 - val_accuracy: 0.9334\n",
            "Epoch 5/10\n",
            "1719/1719 [==============================] - 1s 711us/step - loss: 0.2556 - accuracy: 0.9276 - val_loss: 0.2257 - val_accuracy: 0.9364\n",
            "Epoch 6/10\n",
            "1719/1719 [==============================] - 1s 715us/step - loss: 0.2367 - accuracy: 0.9321 - val_loss: 0.2121 - val_accuracy: 0.9396\n",
            "Epoch 7/10\n",
            "1719/1719 [==============================] - 1s 729us/step - loss: 0.2198 - accuracy: 0.9390 - val_loss: 0.1970 - val_accuracy: 0.9454\n",
            "Epoch 8/10\n",
            "1719/1719 [==============================] - 1s 716us/step - loss: 0.2057 - accuracy: 0.9425 - val_loss: 0.1880 - val_accuracy: 0.9476\n",
            "Epoch 9/10\n",
            "1719/1719 [==============================] - 1s 704us/step - loss: 0.1940 - accuracy: 0.9459 - val_loss: 0.1777 - val_accuracy: 0.9524\n",
            "Epoch 10/10\n",
            "1719/1719 [==============================] - 1s 711us/step - loss: 0.1798 - accuracy: 0.9482 - val_loss: 0.1684 - val_accuracy: 0.9546\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe3b8718590>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28, 1]),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.SGD(learning_rate=1e-2),\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxzjc2lvWtwI",
        "outputId": "58645d40-80a8-4529-ef5b-f442d29d1642"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ],\n",
              "       [0.  , 0.  , 0.99, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
              "       [0.  , 0.97, 0.01, 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  ]],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.round(model.predict(X_new), 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JgbIsCrPWtwI",
        "outputId": "f96576bf-1154-4bb9-97c5-f3d6511368c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'my_mnist_model/0001'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_version = \"0001\"\n",
        "model_name = \"my_mnist_model\"\n",
        "model_path = os.path.join(model_name, model_version)\n",
        "model_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4H2GF0PWtwJ"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "shutil.rmtree(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnuULly_WtwJ",
        "outputId": "cda687c6-91eb-4aab-81d0-a03b18b347ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_mnist_model/0001/assets\n"
          ]
        }
      ],
      "source": [
        "tf.saved_model.save(model, model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXK9joBHWtwJ",
        "outputId": "b494d334-5d64-475c-f083-143f57c3411d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "my_mnist_model/\n",
            "    0001/\n",
            "        saved_model.pb\n",
            "        variables/\n",
            "            variables.data-00000-of-00001\n",
            "            variables.index\n",
            "        assets/\n"
          ]
        }
      ],
      "source": [
        "for root, dirs, files in os.walk(model_name):\n",
        "    indent = '    ' * root.count(os.sep)\n",
        "    print('{}{}/'.format(indent, os.path.basename(root)))\n",
        "    for filename in files:\n",
        "        print('{}{}'.format(indent + '    ', filename))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1gkbgGCWtwK",
        "outputId": "df6b643a-b1f8-4ca8-abd7-6d3f2c88406b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The given SavedModel contains the following tag-sets:\r\n",
            "'serve'\r\n"
          ]
        }
      ],
      "source": [
        "!saved_model_cli show --dir {model_path}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJfIXQ_bWtwK",
        "outputId": "6bf10ec3-a041-4c0b-efcd-33d947d3bcff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The given SavedModel MetaGraphDef contains SignatureDefs with the following keys:\r\n",
            "SignatureDef key: \"__saved_model_init_op\"\r\n",
            "SignatureDef key: \"serving_default\"\r\n"
          ]
        }
      ],
      "source": [
        "!saved_model_cli show --dir {model_path} --tag_set serve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYtEpX5zWtwK",
        "outputId": "cf9cac29-8711-4f75-ba3b-54bb753caf09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The given SavedModel SignatureDef contains the following input(s):\r\n",
            "  inputs['flatten_input'] tensor_info:\r\n",
            "      dtype: DT_FLOAT\r\n",
            "      shape: (-1, 28, 28, 1)\r\n",
            "      name: serving_default_flatten_input:0\r\n",
            "The given SavedModel SignatureDef contains the following output(s):\r\n",
            "  outputs['dense_1'] tensor_info:\r\n",
            "      dtype: DT_FLOAT\r\n",
            "      shape: (-1, 10)\r\n",
            "      name: StatefulPartitionedCall:0\r\n",
            "Method name is: tensorflow/serving/predict\r\n"
          ]
        }
      ],
      "source": [
        "!saved_model_cli show --dir {model_path} --tag_set serve \\\n",
        "                      --signature_def serving_default"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XlvbNBJKWtwK",
        "outputId": "a5f3a044-6c5c-4ec1-a3da-db49dd6fe6ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
            "\n",
            "signature_def['__saved_model_init_op']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['__saved_model_init_op'] tensor_info:\n",
            "        dtype: DT_INVALID\n",
            "        shape: unknown_rank\n",
            "        name: NoOp\n",
            "  Method name is: \n",
            "\n",
            "signature_def['serving_default']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "    inputs['flatten_input'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 28, 28, 1)\n",
            "        name: serving_default_flatten_input:0\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['dense_1'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 10)\n",
            "        name: StatefulPartitionedCall:0\n",
            "  Method name is: tensorflow/serving/predict\n",
            "\n",
            "Defined Functions:\n",
            "  Function Name: '__call__'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          flatten_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='flatten_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "<<45 more lines>>\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #2\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          inputs: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='inputs')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #3\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          flatten_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='flatten_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #4\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          flatten_input: TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='flatten_input')\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n"
          ]
        }
      ],
      "source": [
        "!saved_model_cli show --dir {model_path} --all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y__Ej-_dWtwL"
      },
      "outputs": [],
      "source": [
        "np.save(\"my_mnist_tests.npy\", X_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0kNT1FY7WtwL",
        "outputId": "40bf8835-b9ce-438d-bcc7-285d00334034"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'flatten_input'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_name = model.input_names[0]\n",
        "input_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HMwkciXWtwM",
        "outputId": "67152836-162d-4f1f-ccc3-6d95ed5a4a98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2021-02-18 22:15:30.294109: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-02-18 22:15:30.294306: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "WARNING:tensorflow:From /Users/ageron/miniconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/tools/saved_model_cli.py:445: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
            "INFO:tensorflow:Restoring parameters from my_mnist_model/0001/variables/variables\n",
            "2021-02-18 22:15:30.323498: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:196] None of the MLIR optimization passes are enabled (registered 0 passes)\n",
            "Result for output key dense_1:\n",
            "[[1.1347984e-04 1.5187356e-07 9.7032893e-04 2.7640699e-03 3.7826971e-06\n",
            "  7.6876910e-05 3.9140293e-08 9.9559116e-01 5.3502394e-05 4.2665208e-04]\n",
            " [8.2443521e-04 3.5493889e-05 9.8826385e-01 7.0466995e-03 1.2957400e-07\n",
            "  2.3389691e-04 2.5639210e-03 9.5886099e-10 1.0314899e-03 8.7952529e-08]\n",
            " [4.4693781e-05 9.7028232e-01 9.0526715e-03 2.2641101e-03 4.8766597e-04\n",
            "  2.8800720e-03 2.2714981e-03 8.3753867e-03 4.0439744e-03 2.9759688e-04]]\n"
          ]
        }
      ],
      "source": [
        "!saved_model_cli run --dir {model_path} --tag_set serve \\\n",
        "                     --signature_def serving_default    \\\n",
        "                     --inputs {input_name}=my_mnist_tests.npy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wZib2sTWtwM",
        "outputId": "16b5fa5f-d387-4c50-a001-26b47d7e3eae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ],\n",
              "       [0.  , 0.  , 0.99, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
              "       [0.  , 0.97, 0.01, 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  ]])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.round([[1.1347984e-04, 1.5187356e-07, 9.7032893e-04, 2.7640699e-03, 3.7826971e-06,\n",
        "           7.6876910e-05, 3.9140293e-08, 9.9559116e-01, 5.3502394e-05, 4.2665208e-04],\n",
        "          [8.2443521e-04, 3.5493889e-05, 9.8826385e-01, 7.0466995e-03, 1.2957400e-07,\n",
        "           2.3389691e-04, 2.5639210e-03, 9.5886099e-10, 1.0314899e-03, 8.7952529e-08],\n",
        "          [4.4693781e-05, 9.7028232e-01, 9.0526715e-03, 2.2641101e-03, 4.8766597e-04,\n",
        "           2.8800720e-03, 2.2714981e-03, 8.3753867e-03, 4.0439744e-03, 2.9759688e-04]], 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_JiCGN8WtwN"
      },
      "source": [
        "## TensorFlow Serving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jV5WFOcBWtwN"
      },
      "outputs": [],
      "source": [
        "os.environ[\"MODEL_DIR\"] = os.path.split(os.path.abspath(model_path))[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-X4B3gJWtwN"
      },
      "outputs": [],
      "source": [
        "%%bash --bg\n",
        "nohup tensorflow_model_server \\\n",
        "     --rest_api_port=8501 \\\n",
        "     --model_name=my_mnist_model \\\n",
        "     --model_base_path=\"${MODEL_DIR}\" >server.log 2>&1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9VQQ5nRWtwO",
        "outputId": "e5f12fbc-8de9-4003-96a5-797b66364152"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2021-02-16 22:33:09.323538: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:93] Reading SavedModel debug info (if present) from: /models/my_mnist_model/0001\n",
            "2021-02-16 22:33:09.323642: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2021-02-16 22:33:09.360572: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:206] Restoring SavedModel bundle.\n",
            "2021-02-16 22:33:09.361764: I external/org_tensorflow/tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2200000000 Hz\n",
            "2021-02-16 22:33:09.387713: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:190] Running initialization op on SavedModel bundle at path: /models/my_mnist_model/0001\n",
            "2021-02-16 22:33:09.392739: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:277] SavedModel load for tags { serve }; Status: success: OK. Took 71106 microseconds.\n",
            "2021-02-16 22:33:09.393390: I tensorflow_serving/servables/tensorflow/saved_model_warmup_util.cc:59] No warmup data file found at /models/my_mnist_model/0001/assets.extra/tf_serving_warmup_requests\n",
            "2021-02-16 22:33:09.393847: I tensorflow_serving/core/loader_harness.cc:87] Successfully loaded servable version {name: my_mnist_model version: 1}\n",
            "2021-02-16 22:33:09.398470: I tensorflow_serving/model_servers/server.cc:371] Running gRPC ModelServer at 0.0.0.0:8500 ...\n",
            "[warn] getaddrinfo: address family for nodename not supported\n",
            "2021-02-16 22:33:09.405622: I tensorflow_serving/model_servers/server.cc:391] Exporting HTTP/REST API at:localhost:8501 ...\n",
            "[evhttp_server.cc : 238] NET_LOG: Entering the event loop ...\n"
          ]
        }
      ],
      "source": [
        "!tail server.log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQrUXzdxWtwO"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "input_data_json = json.dumps({\n",
        "    \"signature_name\": \"serving_default\",\n",
        "    \"instances\": X_new.tolist(),\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bv__74b4WtwO",
        "outputId": "d55a5ed6-6e80-41c2-8e55-e2714e6cec92"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\'{\"signature_name\": \"serving_default\", \"instances\": [[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]], [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.32941177487373...'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "repr(input_data_json)[:1500] + \"...\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYMMixpHWtwO"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "SERVER_URL = 'http://localhost:8501/v1/models/my_mnist_model:predict'\n",
        "response = requests.post(SERVER_URL, data=input_data_json)\n",
        "response.raise_for_status() # raise an exception in case of error\n",
        "response = response.json()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3igfcUbWtwP",
        "outputId": "1a85c626-26c7-4157-b001-6b965da955bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['predictions'])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7iT8hpl7WtwP",
        "outputId": "694816e6-e732-4bcf-9581-8b21b8d3ad75"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ],\n",
              "       [0.  , 0.  , 0.99, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
              "       [0.  , 0.97, 0.01, 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  ]])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_proba = np.array(response[\"predictions\"])\n",
        "y_proba.round(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ml7e8xnsWtwP"
      },
      "source": [
        "### Using the gRPC API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHs2_VoFWtwP"
      },
      "outputs": [],
      "source": [
        "from tensorflow_serving.apis.predict_pb2 import PredictRequest\n",
        "\n",
        "request = PredictRequest()\n",
        "request.model_spec.name = model_name\n",
        "request.model_spec.signature_name = \"serving_default\"\n",
        "input_name = model.input_names[0]\n",
        "request.inputs[input_name].CopyFrom(tf.make_tensor_proto(X_new))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4akwO7hWtwP"
      },
      "outputs": [],
      "source": [
        "import grpc\n",
        "from tensorflow_serving.apis import prediction_service_pb2_grpc\n",
        "\n",
        "channel = grpc.insecure_channel('localhost:8500')\n",
        "predict_service = prediction_service_pb2_grpc.PredictionServiceStub(channel)\n",
        "response = predict_service.Predict(request, timeout=10.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZeYl4Y_iWtwc",
        "outputId": "cecc6a16-d34d-4b05-a51d-51b735308d73"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "outputs {\n",
              "  key: \"dense_1\"\n",
              "  value {\n",
              "    dtype: DT_FLOAT\n",
              "    tensor_shape {\n",
              "      dim {\n",
              "        size: 3\n",
              "      }\n",
              "      dim {\n",
              "        size: 10\n",
              "      }\n",
              "    }\n",
              "    float_val: 0.00011425172124290839\n",
              "    float_val: 1.513665068841874e-07\n",
              "    float_val: 0.0009818424005061388\n",
              "    float_val: 0.0027773496694862843\n",
              "    float_val: 3.758880893656169e-06\n",
              "    float_val: 7.6266449468676e-05\n",
              "    float_val: 3.9139514740327286e-08\n",
              "    float_val: 0.995561957359314\n",
              "    float_val: 5.344580131350085e-05\n",
              "    float_val: 0.00043088122038170695\n",
              "    float_val: 0.0008194865076802671\n",
              "    float_val: 3.5498320357874036e-05\n",
              "    float_val: 0.9882420897483826\n",
              "    float_val: 0.00705744931474328\n",
              "    float_val: 1.2937064752804872e-07\n",
              "    float_val: 0.00023402832448482513\n",
              "    float_val: 0.0025743397418409586\n",
              "    float_val: 9.668431610876382e-10\n",
              "    float_val: 0.0010369382798671722\n",
              "    float_val: 8.833576004008137e-08\n",
              "    float_val: 4.441547571332194e-05\n",
              "    float_val: 0.970328688621521\n",
              "    float_val: 0.009044423699378967\n",
              "    float_val: 0.0022599005606025457\n",
              "    float_val: 0.00048672096454538405\n",
              "    float_val: 0.002873610006645322\n",
              "    float_val: 0.002268279204145074\n",
              "    float_val: 0.008354829624295235\n",
              "    float_val: 0.004041312728077173\n",
              "    float_val: 0.0002978229313157499\n",
              "  }\n",
              "}\n",
              "model_spec {\n",
              "  name: \"my_mnist_model\"\n",
              "  version {\n",
              "    value: 1\n",
              "  }\n",
              "  signature_name: \"serving_default\"\n",
              "}"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNQIuEm3Wtwc"
      },
      "source": [
        "Convert the response to a tensor:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "syWvoBT3Wtwd",
        "outputId": "0b397cb3-407d-426b-ca8a-17bdcffb1ec9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ],\n",
              "       [0.  , 0.  , 0.99, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
              "       [0.  , 0.97, 0.01, 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  ]],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output_name = model.output_names[0]\n",
        "outputs_proto = response.outputs[output_name]\n",
        "y_proba = tf.make_ndarray(outputs_proto)\n",
        "y_proba.round(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_k1wCLGiWtwd",
        "outputId": "118df42e-4799-43eb-c0e2-dc432b4cb075"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ],\n",
              "       [0.  , 0.  , 0.99, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
              "       [0.  , 0.97, 0.01, 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  ]])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output_name = model.output_names[0]\n",
        "outputs_proto = response.outputs[output_name]\n",
        "shape = [dim.size for dim in outputs_proto.tensor_shape.dim]\n",
        "y_proba = np.array(outputs_proto.float_val).reshape(shape)\n",
        "y_proba.round(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6G8bCd1Wtwd"
      },
      "source": [
        "## Deploying a new model version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "xa1FtdnWWtwd",
        "outputId": "333f4a09-d08a-447f-9c85-351af650285d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1719/1719 [==============================] - 1s 748us/step - loss: 1.1567 - accuracy: 0.6691 - val_loss: 0.3418 - val_accuracy: 0.9042\n",
            "Epoch 2/10\n",
            "1719/1719 [==============================] - 1s 697us/step - loss: 0.3376 - accuracy: 0.9032 - val_loss: 0.2674 - val_accuracy: 0.9242\n",
            "Epoch 3/10\n",
            "1719/1719 [==============================] - 1s 676us/step - loss: 0.2779 - accuracy: 0.9187 - val_loss: 0.2227 - val_accuracy: 0.9368\n",
            "Epoch 4/10\n",
            "1719/1719 [==============================] - 1s 669us/step - loss: 0.2362 - accuracy: 0.9318 - val_loss: 0.2032 - val_accuracy: 0.9432\n",
            "Epoch 5/10\n",
            "1719/1719 [==============================] - 1s 670us/step - loss: 0.2109 - accuracy: 0.9389 - val_loss: 0.1833 - val_accuracy: 0.9482\n",
            "Epoch 6/10\n",
            "1719/1719 [==============================] - 1s 675us/step - loss: 0.1951 - accuracy: 0.9430 - val_loss: 0.1740 - val_accuracy: 0.9498\n",
            "Epoch 7/10\n",
            "1719/1719 [==============================] - 1s 667us/step - loss: 0.1799 - accuracy: 0.9474 - val_loss: 0.1605 - val_accuracy: 0.9540\n",
            "Epoch 8/10\n",
            "1719/1719 [==============================] - 1s 673us/step - loss: 0.1654 - accuracy: 0.9519 - val_loss: 0.1543 - val_accuracy: 0.9558\n",
            "Epoch 9/10\n",
            "1719/1719 [==============================] - 1s 671us/step - loss: 0.1570 - accuracy: 0.9554 - val_loss: 0.1460 - val_accuracy: 0.9572\n",
            "Epoch 10/10\n",
            "1719/1719 [==============================] - 1s 672us/step - loss: 0.1420 - accuracy: 0.9583 - val_loss: 0.1359 - val_accuracy: 0.9616\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28, 1]),\n",
        "    keras.layers.Dense(50, activation=\"relu\"),\n",
        "    keras.layers.Dense(50, activation=\"relu\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.SGD(learning_rate=1e-2),\n",
        "              metrics=[\"accuracy\"])\n",
        "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRmAhUD2Wtwe",
        "outputId": "608cb277-71fe-45bf-d0d1-55aa37db1f58"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'my_mnist_model/0002'"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_version = \"0002\"\n",
        "model_name = \"my_mnist_model\"\n",
        "model_path = os.path.join(model_name, model_version)\n",
        "model_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XiWt89lkWtwe",
        "outputId": "fa10547c-cead-411c-a3d7-3df4ec771adf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: my_mnist_model/0002/assets\n"
          ]
        }
      ],
      "source": [
        "tf.saved_model.save(model, model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hzqv-e7NWtwe",
        "outputId": "60258300-563f-4e27-e231-533bf2c8edc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "my_mnist_model/\n",
            "    0001/\n",
            "        saved_model.pb\n",
            "        variables/\n",
            "            variables.data-00000-of-00001\n",
            "            variables.index\n",
            "        assets/\n",
            "    0002/\n",
            "        saved_model.pb\n",
            "        variables/\n",
            "            variables.data-00000-of-00001\n",
            "            variables.index\n",
            "        assets/\n"
          ]
        }
      ],
      "source": [
        "for root, dirs, files in os.walk(model_name):\n",
        "    indent = '    ' * root.count(os.sep)\n",
        "    print('{}{}/'.format(indent, os.path.basename(root)))\n",
        "    for filename in files:\n",
        "        print('{}{}'.format(indent + '    ', filename))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lePlfvvrWtwe"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "SERVER_URL = 'http://localhost:8501/v1/models/my_mnist_model:predict'\n",
        "\n",
        "response = requests.post(SERVER_URL, data=input_data_json)\n",
        "response.raise_for_status()\n",
        "response = response.json()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IEi56-UWWtwf",
        "outputId": "4a5223eb-6681-43e9-9e50-478007ad052a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['predictions'])"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T0mHEylGWtwf",
        "outputId": "861c8ac3-bec2-4f1b-d76c-b1bb5f919a2e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ],\n",
              "       [0.  , 0.  , 0.99, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
              "       [0.  , 0.99, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]])"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_proba = np.array(response[\"predictions\"])\n",
        "y_proba.round(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qYnvJJHWtwf"
      },
      "source": [
        "# Deploy the model to Google Cloud AI Platform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Cegg3y5Wtwg"
      },
      "outputs": [],
      "source": [
        "project_id = \"onyx-smoke-242003\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5_aVDQTWtwg"
      },
      "outputs": [],
      "source": [
        "import googleapiclient.discovery\n",
        "\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"my_service_account_private_key.json\"\n",
        "model_id = \"my_mnist_model\"\n",
        "model_path = \"projects/{}/models/{}\".format(project_id, model_id)\n",
        "model_path += \"/versions/v0001/\"\n",
        "ml_resource = googleapiclient.discovery.build(\"ml\", \"v1\").projects()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o83JB7jwWtwg"
      },
      "outputs": [],
      "source": [
        "def predict(X):\n",
        "    input_data_json = {\"signature_name\": \"serving_default\",\n",
        "                       \"instances\": X.tolist()}\n",
        "    request = ml_resource.predict(name=model_path, body=input_data_json)\n",
        "    response = request.execute()\n",
        "    if \"error\" in response:\n",
        "        raise RuntimeError(response[\"error\"])\n",
        "    return np.array([pred[output_name] for pred in response[\"predictions\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_iie9aLWtwg",
        "outputId": "cdf134e4-5aa4-4679-83d9-44227c12ce26"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ],\n",
              "       [0.  , 0.  , 0.99, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
              "       [0.  , 0.99, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]])"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y_probas = predict(X_new)\n",
        "np.round(Y_probas, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kC-FYinWtwg"
      },
      "source": [
        "# Using GPUs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSOSDDK6Wtwh",
        "outputId": "9d284744-c8d0-417b-a7ea-8490ff9536d5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
              " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#tf.test.is_gpu_available() # deprecated\n",
        "tf.config.list_physical_devices('GPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtHknGn2Wtwh",
        "outputId": "8db13fa2-fea1-42d8-cf51-9799561bd4cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.test.gpu_device_name()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_-4yg4QWtwh",
        "outputId": "5627d098-ef2e-4cc3-86a4-01bd45c3d6d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.test.is_built_with_cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cb7OQ4d6Wtwh",
        "outputId": "987b01fc-dde3-4ea8-ec3c-207a708c5373"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 7325002731160755624,\n",
              " name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 11139884032\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "     link {\n",
              "       device_id: 1\n",
              "       type: \"StreamExecutor\"\n",
              "       strength: 1\n",
              "     }\n",
              "   }\n",
              " }\n",
              " incarnation: 7150956550266107441\n",
              " physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\",\n",
              " name: \"/device:GPU:1\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 11139884032\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "     link {\n",
              "       type: \"StreamExecutor\"\n",
              "       strength: 1\n",
              "     }\n",
              "   }\n",
              " }\n",
              " incarnation: 15909479382059415698\n",
              " physical_device_desc: \"device: 1, name: Tesla K80, pci bus id: 0000:00:05.0, compute capability: 3.7\"]"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow.python.client.device_lib import list_local_devices\n",
        "\n",
        "devices = list_local_devices()\n",
        "devices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6OlO8oWWtwi"
      },
      "source": [
        "# Distributed Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8zGBodxWtwi"
      },
      "outputs": [],
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ItPp9wP1Wtwi"
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "    return keras.models.Sequential([\n",
        "        keras.layers.Conv2D(filters=64, kernel_size=7, activation=\"relu\",\n",
        "                            padding=\"same\", input_shape=[28, 28, 1]),\n",
        "        keras.layers.MaxPooling2D(pool_size=2),\n",
        "        keras.layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\",\n",
        "                            padding=\"same\"),\n",
        "        keras.layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\",\n",
        "                            padding=\"same\"),\n",
        "        keras.layers.MaxPooling2D(pool_size=2),\n",
        "        keras.layers.Flatten(),\n",
        "        keras.layers.Dense(units=64, activation='relu'),\n",
        "        keras.layers.Dropout(0.5),\n",
        "        keras.layers.Dense(units=10, activation='softmax'),\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1iW4T4SuWtwj",
        "outputId": "4e2d13d9-f881-4094-dd5a-7d1ac075edfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "550/550 [==============================] - 11s 18ms/step - loss: 1.8163 - accuracy: 0.3979 - val_loss: 0.3446 - val_accuracy: 0.9010\n",
            "Epoch 2/10\n",
            "550/550 [==============================] - 9s 17ms/step - loss: 0.4949 - accuracy: 0.8482 - val_loss: 0.1962 - val_accuracy: 0.9458\n",
            "Epoch 3/10\n",
            "550/550 [==============================] - 10s 17ms/step - loss: 0.3345 - accuracy: 0.9012 - val_loss: 0.1343 - val_accuracy: 0.9622\n",
            "Epoch 4/10\n",
            "550/550 [==============================] - 10s 17ms/step - loss: 0.2537 - accuracy: 0.9267 - val_loss: 0.1049 - val_accuracy: 0.9718\n",
            "Epoch 5/10\n",
            "550/550 [==============================] - 10s 17ms/step - loss: 0.2099 - accuracy: 0.9394 - val_loss: 0.0875 - val_accuracy: 0.9752\n",
            "Epoch 6/10\n",
            "550/550 [==============================] - 10s 17ms/step - loss: 0.1901 - accuracy: 0.9439 - val_loss: 0.0797 - val_accuracy: 0.9772\n",
            "Epoch 7/10\n",
            "550/550 [==============================] - 10s 18ms/step - loss: 0.1672 - accuracy: 0.9506 - val_loss: 0.0745 - val_accuracy: 0.9780\n",
            "Epoch 8/10\n",
            "550/550 [==============================] - 10s 18ms/step - loss: 0.1537 - accuracy: 0.9554 - val_loss: 0.0700 - val_accuracy: 0.9804\n",
            "Epoch 9/10\n",
            "550/550 [==============================] - 10s 18ms/step - loss: 0.1384 - accuracy: 0.9592 - val_loss: 0.0641 - val_accuracy: 0.9818\n",
            "Epoch 10/10\n",
            "550/550 [==============================] - 10s 18ms/step - loss: 0.1358 - accuracy: 0.9602 - val_loss: 0.0611 - val_accuracy: 0.9818\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f014831c110>"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_size = 100\n",
        "model = create_model()\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.SGD(learning_rate=1e-2),\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(X_train, y_train, epochs=10,\n",
        "          validation_data=(X_valid, y_valid), batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "455R9hd0Wtwj",
        "outputId": "c11f3592-fe87-4573-92a2-f1dbfd0d1b27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ]
        }
      ],
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "distribution = tf.distribute.MirroredStrategy()\n",
        "\n",
        "with distribution.scope():\n",
        "    model = create_model()\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                  optimizer=keras.optimizers.SGD(learning_rate=1e-2),\n",
        "                  metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jOmoJJlZWtwj",
        "outputId": "d17c0381-4c39-4072-a797-988796dc8e41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "INFO:tensorflow:batch_all_reduce: 10 all-reduces with algorithm = nccl, num_packs = 1\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:batch_all_reduce: 10 all-reduces with algorithm = nccl, num_packs = 1\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "550/550 [==============================] - 14s 16ms/step - loss: 1.8193 - accuracy: 0.3957 - val_loss: 0.3366 - val_accuracy: 0.9102\n",
            "Epoch 2/10\n",
            "550/550 [==============================] - 7s 13ms/step - loss: 0.4886 - accuracy: 0.8497 - val_loss: 0.1865 - val_accuracy: 0.9478\n",
            "Epoch 3/10\n",
            "550/550 [==============================] - 7s 13ms/step - loss: 0.3305 - accuracy: 0.9008 - val_loss: 0.1344 - val_accuracy: 0.9616\n",
            "Epoch 4/10\n",
            "550/550 [==============================] - 7s 13ms/step - loss: 0.2472 - accuracy: 0.9282 - val_loss: 0.1115 - val_accuracy: 0.9696\n",
            "Epoch 5/10\n",
            "550/550 [==============================] - 7s 13ms/step - loss: 0.2020 - accuracy: 0.9425 - val_loss: 0.0873 - val_accuracy: 0.9748\n",
            "Epoch 6/10\n",
            "550/550 [==============================] - 7s 13ms/step - loss: 0.1865 - accuracy: 0.9458 - val_loss: 0.0783 - val_accuracy: 0.9764\n",
            "Epoch 7/10\n",
            "550/550 [==============================] - 8s 14ms/step - loss: 0.1633 - accuracy: 0.9512 - val_loss: 0.0771 - val_accuracy: 0.9776\n",
            "Epoch 8/10\n",
            "550/550 [==============================] - 8s 14ms/step - loss: 0.1422 - accuracy: 0.9570 - val_loss: 0.0705 - val_accuracy: 0.9786\n",
            "Epoch 9/10\n",
            "550/550 [==============================] - 7s 13ms/step - loss: 0.1408 - accuracy: 0.9603 - val_loss: 0.0627 - val_accuracy: 0.9830\n",
            "Epoch 10/10\n",
            "550/550 [==============================] - 7s 13ms/step - loss: 0.1293 - accuracy: 0.9618 - val_loss: 0.0605 - val_accuracy: 0.9836\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f259bf1a6d0>"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_size = 100\n",
        "model.fit(X_train, y_train, epochs=10,\n",
        "          validation_data=(X_valid, y_valid), batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMf-QeqlWtwk",
        "outputId": "6238a303-b53c-4749-d401-e663b4d3470c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[2.53707055e-10, 7.94509292e-10, 1.02021443e-06, 3.37102080e-08,\n",
              "        4.90816797e-11, 4.37713789e-11, 2.43314297e-14, 9.99996424e-01,\n",
              "        1.50591750e-09, 2.50736753e-06],\n",
              "       [1.11715025e-07, 8.56921833e-05, 9.99914169e-01, 6.31697228e-09,\n",
              "        3.99949344e-11, 4.47976906e-10, 8.46022008e-09, 3.03771834e-08,\n",
              "        2.91782563e-08, 1.95555502e-10],\n",
              "       [4.68117065e-07, 9.99787748e-01, 1.01387537e-04, 2.87393277e-06,\n",
              "        5.29725839e-05, 1.55926125e-06, 2.07211669e-05, 1.76809226e-05,\n",
              "        9.37155255e-06, 5.19965897e-06]], dtype=float32)"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict(X_new)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZQ2Ay9sWtwk"
      },
      "source": [
        "Custom training loop:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDlF1ru-Wtwk",
        "outputId": "a7ef02bd-20d5-4f36-9b83-90c00a33a48e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
            "WARNING:tensorflow:From <ipython-input-9-acb7c62c8738>:36: DistributedIteratorV1.initialize (from tensorflow.python.distribute.input_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use the iterator's `initializer` property instead.\n",
            "Epoch 1/10\n",
            "INFO:tensorflow:batch_all_reduce: 10 all-reduces with algorithm = nccl, num_packs = 1\n",
            "INFO:tensorflow:batch_all_reduce: 10 all-reduces with algorithm = nccl, num_packs = 1\n",
            "Loss: 0.380\n",
            "Epoch 2/10\n",
            "Loss: 0.302\n",
            "Epoch 3/10\n",
            "Loss: 0.285\n",
            "Epoch 4/10\n",
            "Loss: 0.294\n",
            "Epoch 5/10\n",
            "Loss: 0.304\n",
            "Epoch 6/10\n",
            "Loss: 0.310\n",
            "Epoch 7/10\n",
            "Loss: 0.310\n",
            "Epoch 8/10\n",
            "Loss: 0.306\n",
            "Epoch 9/10\n",
            "Loss: 0.303\n",
            "Epoch 10/10\n",
            "Loss: 0.298\n"
          ]
        }
      ],
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "K = keras.backend\n",
        "\n",
        "distribution = tf.distribute.MirroredStrategy()\n",
        "\n",
        "with distribution.scope():\n",
        "    model = create_model()\n",
        "    optimizer = keras.optimizers.SGD()\n",
        "\n",
        "with distribution.scope():\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).repeat().batch(batch_size)\n",
        "    input_iterator = distribution.make_dataset_iterator(dataset)\n",
        "\n",
        "@tf.function\n",
        "def train_step():\n",
        "    def step_fn(inputs):\n",
        "        X, y = inputs\n",
        "        with tf.GradientTape() as tape:\n",
        "            Y_proba = model(X)\n",
        "            loss = K.sum(keras.losses.sparse_categorical_crossentropy(y, Y_proba)) / batch_size\n",
        "\n",
        "        grads = tape.gradient(loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "        return loss\n",
        "\n",
        "    per_replica_losses = distribution.experimental_run(step_fn, input_iterator)\n",
        "    mean_loss = distribution.reduce(tf.distribute.ReduceOp.SUM,\n",
        "                                    per_replica_losses, axis=None)\n",
        "    return mean_loss\n",
        "\n",
        "n_epochs = 10\n",
        "with distribution.scope():\n",
        "    input_iterator.initialize()\n",
        "    for epoch in range(n_epochs):\n",
        "        print(\"Epoch {}/{}\".format(epoch + 1, n_epochs))\n",
        "        for iteration in range(len(X_train) // batch_size):\n",
        "            print(\"\\rLoss: {:.3f}\".format(train_step().numpy()), end=\"\")\n",
        "        print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06QILSnAWtwk"
      },
      "source": [
        "## Training across multiple servers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhI8t0xHWtwl"
      },
      "source": [
        "Kluster TensorFlow adalah sekelompok proses TensorFlow yang berjalan secara paralel, biasanya pada mesin yang berbeda, dan saling berkomunikasi untuk menyelesaikan beberapa pekerjaan, misalnya melatih atau mengeksekusi jaringan neural. Setiap proses TF dalam kluster disebut \"tugas\" (atau \"server TF\"). Proses ini memiliki alamat IP, port, dan tipe (juga disebut peran atau pekerjaannya). Tipe tersebut dapat berupa `\"worker\"`, `\"chief\"`, `\"ps\"` (server parameter) atau `\"evaluator\"`:\n",
        "* Setiap **worker** melakukan komputasi, biasanya pada mesin dengan satu atau beberapa GPU.\n",
        "* **Chief** juga melakukan komputasi, tetapi juga menangani pekerjaan tambahan seperti menulis log TensorBoard atau menyimpan titik pemeriksaan. Ada satu chief dalam kluster, biasanya pekerja pertama (yaitu, pekerja #0).\n",
        "* **Server parameter** (ps) hanya melacak nilai variabel, biasanya pada mesin khusus CPU. * **Evaluator** jelas menangani evaluasi. Biasanya ada satu evaluator dalam satu klaster.\n",
        "\n",
        "Kumpulan tugas yang memiliki tipe yang sama sering disebut \"pekerjaan\". Misalnya, pekerjaan \"pekerja\" adalah kumpulan semua pekerja.\n",
        "\n",
        "Untuk memulai klaster TensorFlow, Anda harus mendefinisikannya terlebih dahulu. Ini berarti menentukan semua tugas (alamat IP, port TCP, dan tipe). Misalnya, spesifikasi klaster berikut mendefinisikan klaster dengan 3 tugas (2 pekerja dan 1 server parameter). Ini adalah kamus dengan satu kunci per pekerjaan, dan nilainya adalah daftar alamat tugas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WFkAx-pWtwl"
      },
      "outputs": [],
      "source": [
        "cluster_spec = {\n",
        "    \"worker\": [\n",
        "        \"machine-a.example.com:2222\",  # /job:worker/task:0\n",
        "        \"machine-b.example.com:2222\"   # /job:worker/task:1\n",
        "    ],\n",
        "    \"ps\": [\"machine-c.example.com:2222\"] # /job:ps/task:0\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnxR76LsWtwl"
      },
      "source": [
        "Setiap tugas dalam kluster dapat berkomunikasi dengan setiap tugas lain di server, jadi pastikan untuk mengonfigurasi firewall Anda guna mengotorisasi semua komunikasi antara mesin-mesin ini pada port-port ini (biasanya lebih mudah jika Anda menggunakan port yang sama pada setiap mesin).\n",
        "\n",
        "Saat tugas dimulai, tugas tersebut perlu diberi tahu tugasnya: jenis dan indeksnya (indeks tugas juga disebut id tugas). Cara umum untuk menentukan semuanya sekaligus (baik spesifikasi kluster maupun jenis dan id tugas saat ini) adalah dengan menyetel variabel lingkungan `TF_CONFIG` sebelum memulai program. Variabel tersebut harus berupa kamus berkode JSON yang berisi spesifikasi kluster (di bawah kunci `\"cluster\"`), dan jenis serta indeks tugas yang akan dimulai (di bawah kunci `\"task\"`). Misalnya, variabel lingkungan `TF_CONFIG` berikut mendefinisikan kluster yang sama seperti di atas, dengan 2 pekerja dan 1 server parameter, dan menetapkan bahwa tugas yang akan dimulai adalah pekerja #1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2BMOTk8UWtwl",
        "outputId": "d7549651-7bc7-4da6-db63-fe500f36619d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'{\"cluster\": {\"worker\": [\"machine-a.example.com:2222\", \"machine-b.example.com:2222\"], \"ps\": [\"machine-c.example.com:2222\"]}, \"task\": {\"type\": \"worker\", \"index\": 1}}'"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "os.environ[\"TF_CONFIG\"] = json.dumps({\n",
        "    \"cluster\": cluster_spec,\n",
        "    \"task\": {\"type\": \"worker\", \"index\": 1}\n",
        "})\n",
        "os.environ[\"TF_CONFIG\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEw3FeoiWtwm"
      },
      "source": [
        "Kelas `TFConfigClusterResolver` TensorFlow membaca konfigurasi kluster dari variabel lingkungan ini:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4JeZFqEHWtwm",
        "outputId": "bdf17335-dfaf-4959-933a-ae631b9602cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ClusterSpec({'ps': ['machine-c.example.com:2222'], 'worker': ['machine-a.example.com:2222', 'machine-b.example.com:2222']})"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "resolver = tf.distribute.cluster_resolver.TFConfigClusterResolver()\n",
        "resolver.cluster_spec()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UnEhKpmYWtwm",
        "outputId": "c1d2a451-810c-4f3f-d6f0-c505a56c34cc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'worker'"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "resolver.task_type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KRiV8JNWtwm",
        "outputId": "bceff7d6-b121-4c5e-e152-e2f3d4233112"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "resolver.task_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4cYTLSjWtwn",
        "outputId": "d4f3446d-aba8-47a6-9a39-4c7f3e910368"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting my_mnist_multiworker_task.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile my_mnist_multiworker_task.py\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import time\n",
        "\n",
        "# At the beginning of the program\n",
        "distribution = tf.distribute.MultiWorkerMirroredStrategy()\n",
        "\n",
        "resolver = tf.distribute.cluster_resolver.TFConfigClusterResolver()\n",
        "print(\"Starting task {}{}\".format(resolver.task_type, resolver.task_id))\n",
        "\n",
        "# Only worker #0 will write checkpoints and log to TensorBoard\n",
        "if resolver.task_id == 0:\n",
        "    root_logdir = os.path.join(os.curdir, \"my_mnist_multiworker_logs\")\n",
        "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
        "    run_dir = os.path.join(root_logdir, run_id)\n",
        "    callbacks = [\n",
        "        keras.callbacks.TensorBoard(run_dir),\n",
        "        keras.callbacks.ModelCheckpoint(\"my_mnist_multiworker_model.h5\",\n",
        "                                        save_best_only=True),\n",
        "    ]\n",
        "else:\n",
        "    callbacks = []\n",
        "\n",
        "# Load and prepare the MNIST dataset\n",
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
        "X_train_full = X_train_full[..., np.newaxis] / 255.\n",
        "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "\n",
        "with distribution.scope():\n",
        "    model = keras.models.Sequential([\n",
        "        keras.layers.Conv2D(filters=64, kernel_size=7, activation=\"relu\",\n",
        "                            padding=\"same\", input_shape=[28, 28, 1]),\n",
        "        keras.layers.MaxPooling2D(pool_size=2),\n",
        "        keras.layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\",\n",
        "                            padding=\"same\"),\n",
        "        keras.layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\",\n",
        "                            padding=\"same\"),\n",
        "        keras.layers.MaxPooling2D(pool_size=2),\n",
        "        keras.layers.Flatten(),\n",
        "        keras.layers.Dense(units=64, activation='relu'),\n",
        "        keras.layers.Dropout(0.5),\n",
        "        keras.layers.Dense(units=10, activation='softmax'),\n",
        "    ])\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                  optimizer=keras.optimizers.SGD(learning_rate=1e-2),\n",
        "                  metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(X_train, y_train, validation_data=(X_valid, y_valid),\n",
        "          epochs=10, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PijRKx-1Wtwn"
      },
      "source": [
        "Dalam aplikasi dunia nyata, biasanya hanya ada satu pekerja per mesin, tetapi dalam contoh ini, kami menjalankan kedua pekerja pada mesin yang sama, sehingga keduanya akan mencoba menggunakan semua RAM GPU yang tersedia (jika mesin ini memiliki GPU), dan ini kemungkinan akan menyebabkan kesalahan Kehabisan Memori (OOM). Untuk menghindari hal ini, kami dapat menggunakan variabel lingkungan `CUDA_VISIBLE_DEVICES` untuk menetapkan GPU yang berbeda untuk setiap pekerja. Atau, kami dapat menonaktifkan dukungan GPU, seperti ini:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GK60V3e0Wtwn"
      },
      "outputs": [],
      "source": [
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HTdiYSdWtwo"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "\n",
        "cluster_spec = {\"worker\": [\"127.0.0.1:9901\", \"127.0.0.1:9902\"]}\n",
        "\n",
        "for index, worker_address in enumerate(cluster_spec[\"worker\"]):\n",
        "    os.environ[\"TF_CONFIG\"] = json.dumps({\n",
        "        \"cluster\": cluster_spec,\n",
        "        \"task\": {\"type\": \"worker\", \"index\": index}\n",
        "    })\n",
        "    subprocess.Popen(\"python my_mnist_multiworker_task.py\", shell=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R10qEASOWtwp",
        "outputId": "c0e8e913-8567-4016-8391-89cf864114f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([7, 2, 1])"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "model = keras.models.load_model(\"my_mnist_multiworker_model.h5\")\n",
        "Y_pred = model.predict(X_new)\n",
        "np.argmax(Y_pred, axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ“˜ Chapter 19: Training and Deploying TensorFlow Models at Scale\n",
        "\n",
        "\n",
        "\n",
        "##  Tujuan Bab\n",
        "\n",
        "* Memahami teknik dan arsitektur untuk melatih model TensorFlow secara skala besar.\n",
        "* Menguasai praktik terbaik deployment model ML ke produksi dengan efisien dan scalable.\n",
        "* Memahami integrasi pipeline ML, monitoring, dan continuous training.\n",
        "\n",
        "\n",
        "\n",
        "## 1. **Challenges of Large-Scale Training**\n",
        "\n",
        "* Dataset besar â†’ memerlukan **distributed training** dan **data pipeline efisien**.\n",
        "* Model besar â†’ membutuhkan **resource komputasi tinggi**, GPU/TPU.\n",
        "* Menghindari overfitting dan memastikan generalisasi.\n",
        "* Deployment membutuhkan model yang:\n",
        "\n",
        "  * Fast inference\n",
        "  * Scalable dan reliable\n",
        "  * Mudah dipantau dan diperbarui\n",
        "\n",
        "\n",
        "\n",
        "## 2. **Distributed Training dengan TensorFlow**\n",
        "\n",
        "### 2.1 Distributed Strategy API\n",
        "\n",
        "TensorFlow menyediakan beberapa strategi untuk parallel dan distributed training:\n",
        "\n",
        "| Strategy                      | Keterangan                                      |\n",
        "| ----------------------------- | ----------------------------------------------- |\n",
        "| `MirroredStrategy`            | Data parallelism di satu mesin dengan multi-GPU |\n",
        "| `MultiWorkerMirroredStrategy` | Distributed data parallelism di beberapa mesin  |\n",
        "| `TPUStrategy`                 | Khusus TPU di Google Cloud                      |\n",
        "\n",
        "\n",
        "\n",
        "### 2.2 Contoh penggunaan `MirroredStrategy`\n",
        "\n",
        "```python\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "with strategy.scope():\n",
        "    model = create_model()\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "model.fit(dataset, epochs=10)\n",
        "```\n",
        "\n",
        "* `strategy.scope()` menjamin semua variabel dan operasi model di-replicate ke semua device.\n",
        "\n",
        "\n",
        "\n",
        "## 3. **Input Pipeline untuk Scale**\n",
        "\n",
        "### 3.1 Gunakan `tf.data` API\n",
        "\n",
        "* Pipeline data efisien dengan metode `map()`, `batch()`, `prefetch()`, `shuffle()`.\n",
        "* Contoh pipeline:\n",
        "\n",
        "```python\n",
        "def preprocess(image, label):\n",
        "    image = tf.image.resize(image, [224, 224])\n",
        "    image = image / 255.0\n",
        "    return image, label\n",
        "\n",
        "dataset = tf.data.TFRecordDataset(filenames)\n",
        "dataset = dataset.map(preprocess).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "### 3.2 TFRecord Format\n",
        "\n",
        "* Format penyimpanan data yang efisien dan mudah di-streaming.\n",
        "* Cocok untuk dataset besar.\n",
        "\n",
        "\n",
        "\n",
        "## 4. **Checkpointing dan TensorBoard**\n",
        "\n",
        "### 4.1 Checkpointing\n",
        "\n",
        "* Simpan state model secara periodik untuk pemulihan (recovery).\n",
        "* Contoh:\n",
        "\n",
        "```python\n",
        "checkpoint_path = \"training_1/cp.ckpt\"\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                         save_weights_only=True,\n",
        "                                                         verbose=1)\n",
        "model.fit(dataset, epochs=10, callbacks=[checkpoint_callback])\n",
        "```\n",
        "\n",
        "### 4.2 Monitoring dengan TensorBoard\n",
        "\n",
        "* Visualisasi loss, accuracy, dan metrics lain.\n",
        "* Logging menggunakan:\n",
        "\n",
        "```python\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='./logs')\n",
        "model.fit(dataset, epochs=10, callbacks=[tensorboard_callback])\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "## 5. **Model Deployment**\n",
        "\n",
        "### 5.1 Export Model\n",
        "\n",
        "* Ekspor model Keras ke format SavedModel:\n",
        "\n",
        "```python\n",
        "model.save(\"saved_model/my_model\")\n",
        "```\n",
        "\n",
        "* Format ini portable dan dapat digunakan di berbagai platform.\n",
        "\n",
        "\n",
        "\n",
        "### 5.2 Serving Model dengan TensorFlow Serving\n",
        "\n",
        "* TensorFlow Serving adalah server khusus untuk serving model TensorFlow di production.\n",
        "* Mendukung versioning model dan update tanpa downtime.\n",
        "* Contoh command:\n",
        "\n",
        "```bash\n",
        "tensorflow_model_server --rest_api_port=8501 --model_name=my_model --model_base_path=/path/to/saved_model/my_model/\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "### 5.3 Deployment di Cloud\n",
        "\n",
        "* Cloud platform seperti Google AI Platform, AWS SageMaker, Azure ML menyediakan managed service untuk training dan deployment.\n",
        "* Integrasi dengan CI/CD pipeline untuk retraining otomatis.\n",
        "\n",
        "\n",
        "\n",
        "## 6. **Optimasi Model untuk Deployment**\n",
        "\n",
        "### 6.1 Model Quantization\n",
        "\n",
        "* Mengurangi ukuran model dan mempercepat inference.\n",
        "* Tersedia post-training quantization:\n",
        "\n",
        "```python\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(\"saved_model/my_model\")\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_model = converter.convert()\n",
        "```\n",
        "\n",
        "### 6.2 Pruning dan Clustering\n",
        "\n",
        "* Mengurangi kompleksitas model dengan menghapus koneksi kecil (pruning).\n",
        "* Clustering bobot untuk kompresi.\n",
        "\n",
        "\n",
        "\n",
        "## 7. **Continuous Training & Monitoring**\n",
        "\n",
        "* Automasi retraining model dengan data terbaru.\n",
        "* Monitoring performa model secara real-time untuk deteksi data drift atau degradasi.\n",
        "\n",
        "\n",
        "\n",
        "## 8. **Best Practices**\n",
        "\n",
        "| Aspek                | Praktik Terbaik                                      |\n",
        "| -------------------- | ---------------------------------------------------- |\n",
        "| Data Pipeline        | Pipeline paralel, prefetch, cache                    |\n",
        "| Distributed Training | Gunakan `strategy` API, batch besar                  |\n",
        "| Checkpointing        | Sering simpan checkpoint dan gunakan untuk recovery  |\n",
        "| Deployment           | Gunakan SavedModel, TensorFlow Serving, quantization |\n",
        "| Monitoring           | TensorBoard, logging metrik, alerting                |\n",
        "| Automation           | Integrasi CI/CD, retraining otomatis                 |\n",
        "\n",
        "\n",
        "\n",
        "## ðŸ“ˆ **Kesimpulan**\n",
        "\n",
        "Training dan deployment model TensorFlow skala besar memerlukan kombinasi teknologi dan praktik modern:\n",
        "\n",
        "* **Distributed training** dan optimasi pipeline data untuk memanfaatkan resource komputasi secara efisien.\n",
        "* **Checkpointing dan monitoring** untuk menjaga stabilitas dan performa.\n",
        "* **Deployment yang scalable** menggunakan TensorFlow Serving atau platform cloud.\n",
        "* **Optimasi model** seperti quantization untuk inference yang cepat dan ringan.\n",
        "* Pendekatan **continuous training** dan monitoring membantu menjaga performa model dalam produksi.\n",
        "\n"
      ],
      "metadata": {
        "id": "Xeie0CRRX6KB"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}